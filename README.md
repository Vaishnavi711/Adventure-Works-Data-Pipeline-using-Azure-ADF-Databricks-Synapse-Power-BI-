## Overview ğŸ“

#### This project demonstrates a real-world, end-to-end data engineering pipeline built on Microsoft Azure, using the Adventure Works dataset. It showcases how to ingest, process, store, and visualize data using modern, enterprise-grade cloud tools.

## Step-1 Azure Data Factory (ADF) ğŸ”„ğŸ­

- **Data Ingestion**: Pulled data from **GitHub (via HTTP)** into **Azure Data Lake (ADLS)**.\
- **Created Static & Dynamic Pipelines ğŸ”„**:
  - **Static Pipelines**: Processed fixed datasets (e.g., daily Products data ğŸ“Š).
  - **Dynamic Pipelines**: Parameterized to handle **multiple files/folders**, ensuring **scalability & reusability**.
- **Used Activities**:
  - **Copy Activity ğŸ“¥**: Loaded JSON files from **GitHub** into **ADLS**.
  - **Lookup Activity ğŸ”**: Retrieved configuration & metadata for dynamic processing.
  - **ForEach Activity ğŸ”**: Iterated over multiple JSON files to apply transformations dynamically.
- **Data Transformation**: Leveraged **Mapping Data Flows** to clean, join, and standardize data.
- - **Orchestration âš™ï¸**: Managed end-to-end data workflows by controlling pipeline execution order, dependencies, and monitoring pipeline runs.
- **Integration**: Connected seamlessly with **Azure Databricks (processing)** and **Azure Synapse (analytics)**.


## Step-2 Azure Databricks (Transformation) âš¡
- **Connected ADLS to Databricks ğŸ”** using **Azure AD App Registration (Service Principal)** with secure OAuth-based access.
- **Purpose**: Processed raw **Bronze layer** data into curated **Silver layer** for analytics.
- **Data Cleaning & Transformation ğŸ§¹**: 
  - Removed duplicates, handled missing values, and standardized data formats.
  - Applied business rules and transformations using **PySpark**.
- **Schema Enforcement ğŸ“**: Ensured consistent structure across datasets.
- **Integration ğŸ”—**: Read input from **ADLS (Bronze)** and wrote transformed outputs back to **ADLS (Silver)**.
- **Reusability & Scalability ğŸš€**: Built modular notebooks and parameterized jobs for dynamic data processing.

## Step-3 Azure Synapse Analytics (Gold Layer) ğŸ“Š


- **Purpose**: Served as the **analytics & reporting layer (Gold)** for business-ready data.
- **Data Consumption**: Queried curated **Silver data from ADLS** using **serverless SQL pools**.
- **Data Modeling ğŸ“**: Created **views** for KPIs and business insights and created External table from existing table and served in **golden layer**
- **Integration ğŸ”—**: Provided created external datasets to **Power BI** for visualization and reporting.

## Step-4 Power BI (Visualization Layer) ğŸ“ˆ



- **Purpose**: Delivered **interactive dashboards & reports** for business stakeholders.  
- **Data Source ğŸ”—**: Connected directly to **Azure Synapse (Gold Layer)** for real-time analytics.  
- **Visualizations ğŸ“Š**: Built KPIs, trend analysis, and sales performance dashboards.  
  






